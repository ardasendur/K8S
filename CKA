Core Concepts
Master Node : 
 - > etcd (DB of cluster)
 - > kube api server (external user operation)
 - > kube-scheduler
 - > controller-manager (node-controller , replication controller)
 Master : plan,schedule,control and manage 
 Worker Node: 
  -> kubelet ( kube api server talk with kubelet)
  -> kube-proxy (provide communication between nodes)
  -> Container run time (docker ,rocket)

 ETCD:
  - key-value store 
   Install ETCD
      Download binaries : curl -L https://github.com/etcd-io/etcd/releases/download/v3.3.11/etcdv3.3.11-linux-amd64.tar.gz -o etcd-v3.3.11-linux-amd64.tar.gz
      Extract : tar xzvf etcd-v3.3.11-linux-amd64.tar.gz
      Run ETCD Service : ./etcd - 
   - > Nodes, Pods, Configs,Secrets,Accounts,Roles,Bindings,Others information store in etcd
   - > Every info whenever you call kubectl get command is from etcd server.
   - > default port for etcd is : 2379
   - > You can install etcd two ways : manual or kubeadm
   - > etcdctl id the cli tool used to intract with etcd
   - > ETCDCTL can intract with etcd server using 2 api version 2 and version 3.
   - > export ETCDCTL_API=3
  Kubernetess Api Server: 
    1- Auth user
    2- Validate request
    3- Retrieve data
    4- Update ETCD
    5- Scheduler (continiously monitors api server and realize that any pods with no assigned nodes)
    6- Kubelet
    7- ETCD update
To summarize: the kube api-server is responsible for Authenticating and validating request,retriving data
In fact kube api server is the only component that interacts directly with etcd datastore 
View api-server opitons : cat /etc/kubernetess/manifest/kube-apiserver.yaml
ps -aux | grep kube-apiserver

Kube Controller Manager : 
 - A controller is a process that continiously monitors the state of various components within the system
 - Node controller is responsible for monitoring the status of the nodes and taking necassary action (keep application runnig)
 - Replication controller is responsible to hold the system desired state.
- kubeadm does not deploy  kubelets
- The node controller checks the status of the nodes every 5 seconds. (node monitor period : 5s)
- Node monitor grace period : 40s
- Kubernetess has many controller like (Deploymnet, Namespace,Endpoint,Job,CronJob etc.)
- When you install the k8s controller manager the different controllers get installed  as well

Kube Proxy: 
Each node in kubernetess cluster can reach any other nodes in cluster.
If the app is exposed with servie, they can talk with the name of the service

Multi-Container Pods:
  - > Two containers can communicate  each other as "localhost" ,they share the same network namespace

YAML:
 - kind is a type object
Replica Set: 
 - kubectl scale replicaset --replicas=2 <Name of Replica Set>
Deployment: (It is kubernetess object)
 - kubectl create -f deployment
 - kubectl get deployments
 - kubectl get replicaset
 - kubectl get pods
 - kubectl get all
 Tips : 
  kubectl run --generato=run-pod/v1 nginx --image=nginx
  Generate POD manifest yaml - > kubectl run --generator=run-pod/v1 nginx --image=nginx  --dry-run-o yaml
To get number of  pods or ns :
 kubectl get pods --no-headers | wc -l

If pods are in same namespace , they can speak with each other with name
Otherwise, they can reach it by using , pod + ns+svc+cluster+local
 
 Daemon Set : 
     Daemon set ensures that one copy of the pods is always present all nodes in the cluster.
     Daemon set is best fit fr monitoring and logs viewer.
     Kube proxy is using deamon set acuttaly ,it spread all nodes in cluster.
     kubectl create deamonset
     kubectl describe daemonset
     kubectl get ds
  
  Daemon set and  static pod ignored for kube-scheduler
